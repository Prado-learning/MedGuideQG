import torch
from transformers import AutoModelForCausalLM, AutoTokenizer
import os

# åŠ è½½ tokenizer
LORA_MODEL_PATH = "/root/autodl-tmp/MedGuideQG/lora_medical"
MODEL_NAME = "Qwen/Qwen2.5-7B-Instruct"

tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)

# åŠ è½½åŸºç¡€æ¨¡å‹
model = AutoModelForCausalLM.from_pretrained(
    MODEL_NAME,
    load_in_8bit=True,  # å…¼å®¹ bitsandbytes é‡åŒ–
    device_map="auto",
)

# åŠ è½½ LoRA è®­ç»ƒå¥½çš„æƒé‡
if os.path.exists(LORA_MODEL_PATH):
    model = PeftModel.from_pretrained(model, LORA_MODEL_PATH)
    print("âœ… åŠ è½½ LoRA è®­ç»ƒæ¨¡å‹æˆåŠŸï¼")
else:
    print("âš ï¸ æœªæ‰¾åˆ° LoRA è®­ç»ƒæ¨¡å‹ï¼Œä½¿ç”¨åŸå§‹æ¨¡å‹ï¼")

# è®¾å¤‡é€‰æ‹©
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"
model.to(DEVICE)

def generate_response(user_input):
    """ç”Ÿæˆ AI å›ç­”"""
    messages = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½åº·å¤åŒ»å­¦ä¸“å®¶"},
        {"role": "user", "content": user_input},
    ]

    # æ ¼å¼åŒ–ä¸ºæ¨¡å‹æ‰€éœ€çš„æ ¼å¼
    text = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)

    # è½¬æ¢ä¸ºæ¨¡å‹è¾“å…¥
    model_inputs = tokenizer([text], return_tensors="pt").to(DEVICE)

    # ç”Ÿæˆå›ç­”
    with torch.no_grad():
        generated_ids = model.generate(
            **model_inputs,
            max_new_tokens=256,  # é™åˆ¶ç”Ÿæˆé•¿åº¦
        )

    # æå–ç”Ÿæˆçš„å†…å®¹
    generated_ids = [
        output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)
    ]

    # è§£ç æ¨¡å‹è¾“å‡º
    response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]
    return response

def interactive_medical_qna():
    """äº¤äº’å¼ä¸‰é˜¶æ®µåŒ»ç–—é—®ç­”"""
    
    print("\nğŸ©º **æ‚¨å¥½ï¼Œè¿™é‡Œæ˜¯æ™ºæ…§åŒ»ç–—å°åŠ©æ‰‹ï¼Œè¯·æ‚¨æè¿°æ‚¨çš„ç—…æƒ…ã€‚**\n")
    
    # **ç¬¬ä¸€è½®: ç”¨æˆ·è¾“å…¥ç—…æƒ…æè¿°**
    patient_input = input("ğŸ“ æ‚£è€…: ")
    if patient_input.lower() == "exit":
        print("ğŸ‘‹ é€€å‡ºé—®ç­”ç³»ç»Ÿã€‚")
        return
    
    # **ç¬¬ä¸€è½®: è¯Šæ–­ & é‰´åˆ«è¯Šæ–­**
    messages_round1 = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½åº·å¤åŒ»å­¦ä¸“å®¶"},
        {"role": "user", "content": f"ä½ å°†æ ¹æ®æ‚£è€…åœ¨{patient_input}ä¸­æä¾›çš„ä¿¡æ¯ï¼Œä»”ç»†æ€è€ƒï¼Œç»™å‡º1ä¸ªå¯èƒ½çš„è¯Šæ–­ã€‚\n"
                                   "éšåæ ¹æ®å¯èƒ½æ€§ä»é«˜åˆ°ä½ï¼Œä¾æ¬¡ç»™å‡º3è‡³5ä¸ªå¯èƒ½çš„é‰´åˆ«è¯Šæ–­ã€‚\n"
                                   "è¯·åªå›ç­”è¯Šæ–­å’Œé‰´åˆ«è¯Šæ–­ï¼Œä¸è¦åœ¨å›ç­”ä¸­åŒ…å«å…¶ä»–å†…å®¹ã€‚"}
    ]
    diagnosis_response = generate_response(patient_input)
    print("\nğŸ”¹ **ç¬¬ä¸€è½® (è¯Šæ–­ & é‰´åˆ«è¯Šæ–­):**\n", diagnosis_response)

    # **ç¬¬äºŒè½®: æœºå™¨ç”Ÿæˆæé—®**
    print(f"æ ¹æ®æ¨¡å‹çš„è¯Šæ–­ï¼š{diagnosis_response}\n")
    print("ç³»ç»Ÿæé—®: æ ¹æ®è¯Šç–—æŒ‡å—ï¼Œä½ èƒ½å¦æ›´è¯¦ç»†åœ°æè¿°è‡ªå·±çš„é—®é¢˜å‘¢ï¼Ÿ\n")
    
    # **ç¬¬äºŒè½®: ç”¨æˆ·è¾“å…¥äºŒè½®é—®é¢˜**
    second_input = input("âœï¸ æ‚£è€…: ")
    if second_input.lower() == "exit":
        print("ğŸ‘‹ é€€å‡ºé—®ç­”ç³»ç»Ÿã€‚")
        return
    
    # **ç¬¬äºŒè½®: è¯Šç–—æŒ‡å— & æ²»ç–—æ–¹æ¡ˆ**
    messages_round2 = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½åº·å¤åŒ»å­¦ä¸“å®¶"},
        {"role": "user", "content": f"æ ¹æ®ä¸Šè¿°å›ç­”ï¼Œä½ è€ƒè™‘æ‚£è€…çš„è¯Šæ–­æ˜¯{diagnosis_response}ã€‚\n"
                                   "è¿™æ˜¯è¿™ä¸ªç–¾ç—…çš„è¯Šç–—æŒ‡å—{æŒ‡å—}ï¼Œè¯·æ ¹æ®æŒ‡å—å›ç­”:\n"
                                   "1. æ‚£è€…ç—…æƒ…åˆ†æ\n"
                                   "2. æœ€ç»ˆè¯Šæ–­\n"
                                   "3. è¿›ä¸€æ­¥æ£€æŸ¥åŠæ²»ç–—æ–¹æ¡ˆ\n"
                                   "è¯·å¼•ç”¨è¯Šç–—æŒ‡å—çš„åŸæ–‡ã€‚"}
    ]
    treatment_response = generate_response(second_input)
    print("\nğŸ”¹ **ç¬¬äºŒè½® (ç—…æƒ…åˆ†æ & æ²»ç–—æ–¹æ¡ˆ):**\n", treatment_response)

    # **ç¬¬ä¸‰è½®: æœºå™¨ç”Ÿæˆæé—®**
    print(f" æ ¹æ®æ¨¡å‹çš„æ²»ç–—å»ºè®®ï¼š{treatment_response}\n")
    print("ç³»ç»Ÿæé—®: æ ¹æ®è¿™ä¸ªæŒ‡å—ï¼Œæ‚¨èƒ½å›ç­”è¿™ä¸ªæ˜¯å¦ç¬¦åˆè‡ªå·±çš„é—®é¢˜ï¼Œæ˜¯å¦æœ‰å…¶ä»–ç—‡çŠ¶éœ€è¦è¡¥å……å—ï¼Ÿ\n")
    
    # **ç¬¬ä¸‰è½®: ç”¨æˆ·è¾“å…¥ä¸‰è½®é—®é¢˜**
    third_input = input("âœï¸ æ‚£è€…: ")
    if third_input.lower() == "exit":
        print("ğŸ‘‹ é€€å‡ºé—®ç­”ç³»ç»Ÿã€‚")
        return
    
    # **ç¬¬ä¸‰è½®: åŒ»ç”Ÿè§’è‰²æ€»ç»“ & è¯¦ç»†å›ç­”**
    messages_round3 = [
        {"role": "system", "content": "ä½ æ˜¯ä¸€ä½åº·å¤åŒ»å­¦ä¸“å®¶"},
        {"role": "user", "content": "è¯·æ€»ç»“å¹¶ä»¥åŒ»ç”Ÿè§’è‰²å›ç­”æ‚£è€…ã€‚"}
    ]
    final_response = generate_response(third_input)
    print("\nğŸ”¹ **ç¬¬ä¸‰è½® (åŒ»ç”Ÿè¯¦ç»†å›ç­”æ‚£è€…):**\n", final_response)

    print("\nâœ… **é—®ç­”ç»“æŸï¼Œæ„Ÿè°¢æ‚¨çš„å’¨è¯¢ï¼**")

if __name__ == "__main__":
    interactive_medical_qna()
